{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : \n",
      "\n",
      "[[8.450e+03 7.000e+00 5.000e+00 ... 0.000e+00 5.480e+02 1.000e+00]\n",
      " [9.600e+03 6.000e+00 8.000e+00 ... 1.000e+00 4.600e+02 1.000e+00]\n",
      " [1.125e+04 7.000e+00 5.000e+00 ... 1.000e+00 6.080e+02 1.000e+00]\n",
      " ...\n",
      " [9.042e+03 7.000e+00 9.000e+00 ... 2.000e+00 2.520e+02 1.000e+00]\n",
      " [9.717e+03 5.000e+00 6.000e+00 ... 0.000e+00 2.400e+02 0.000e+00]\n",
      " [9.937e+03 5.000e+00 6.000e+00 ... 0.000e+00 2.760e+02 0.000e+00]]\n",
      "\n",
      "Dimensions of dataset : (1460, 11)\n"
     ]
    }
   ],
   "source": [
    "data_orig = np.genfromtxt('data/housepricedata.csv',delimiter=',',skip_header=1)\n",
    "print(\"Dataset : \\n\\n\"+ str(data_orig))\n",
    "print(\"\\nDimensions of dataset : \"+str(data_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed for np.random\n",
    "seed=16\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling imported original dataset\n",
    "np.random.shuffle(data_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled dataset with (Seed 0) :\n",
      "\n",
      "[[3.2668e+04 6.0000e+00 3.0000e+00 ... 2.0000e+00 4.8400e+02 1.0000e+00]\n",
      " [9.4900e+03 6.0000e+00 7.0000e+00 ... 2.0000e+00 2.4000e+02 0.0000e+00]\n",
      " [7.0150e+03 5.0000e+00 4.0000e+00 ... 1.0000e+00 3.5200e+02 0.0000e+00]\n",
      " ...\n",
      " [8.9300e+03 6.0000e+00 5.0000e+00 ... 0.0000e+00 5.3900e+02 0.0000e+00]\n",
      " [3.1960e+03 7.0000e+00 5.0000e+00 ... 1.0000e+00 4.2000e+02 1.0000e+00]\n",
      " [1.6770e+04 7.0000e+00 5.0000e+00 ... 0.0000e+00 4.8600e+02 1.0000e+00]]\n",
      "\n",
      "(1460, 11)\n"
     ]
    }
   ],
   "source": [
    "#Shuffled dataset\n",
    "print(\"Shuffled dataset with (Seed \"+str(seed) +\") :\\n\\n\"+str(data_orig))\n",
    "print(\"\\n\"+str(data_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Y   :[1. 0. 0. ... 0. 1. 1.]\n",
      "Shape of Y : (1460,)\n"
     ]
    }
   ],
   "source": [
    "#Extacting Y\n",
    "y_orig = data_orig[:,-1]\n",
    "print(\"Output Y   :\"+str(y_orig))\n",
    "print(\"Shape of Y : \"+str(y_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (1, 1460)\n"
     ]
    }
   ],
   "source": [
    "Y = np.reshape(y_orig,(y_orig.shape[0],1)).T    \n",
    "print(\"Shape of Y: \"+ str(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input set : \n",
      "\n",
      "[[3.2668e+04 9.4900e+03 7.0150e+03 ... 8.9300e+03 3.1960e+03 1.6770e+04]\n",
      " [6.0000e+00 6.0000e+00 5.0000e+00 ... 6.0000e+00 7.0000e+00 7.0000e+00]\n",
      " [3.0000e+00 7.0000e+00 4.0000e+00 ... 5.0000e+00 5.0000e+00 5.0000e+00]\n",
      " ...\n",
      " [9.0000e+00 5.0000e+00 5.0000e+00 ... 8.0000e+00 7.0000e+00 7.0000e+00]\n",
      " [2.0000e+00 2.0000e+00 1.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
      " [4.8400e+02 2.4000e+02 3.5200e+02 ... 5.3900e+02 4.2000e+02 4.8600e+02]]\n"
     ]
    }
   ],
   "source": [
    "#Extracting vectorized input feature X (transposed)\n",
    "x_shuffled = data_orig[:,0:-1].T\n",
    "print(\"Input set : \\n\\n\" +str(x_shuffled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1460)\n"
     ]
    }
   ],
   "source": [
    "print(x_shuffled.shape)\n",
    "X=x_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed of Randomization   : 0\n",
      "\n",
      "Shape of Training set X : (10, 1168)\n",
      "Shape of Training set Y : (1, 1168)\n",
      "\n",
      "Shape of Test set   X   : (10, 292)\n",
      "Shape of Test set Y     : (1, 292)\n"
     ]
    }
   ],
   "source": [
    "#Splitting into Train, Test sets ( with a fixed seed )\n",
    "train_split_percent = 80\n",
    "test_split_percent = 20\n",
    "\n",
    "train_X , test_X = X[:, : int( (train_split_percent/100)*X.shape[1])] , X[:,int( (train_split_percent/100)*X.shape[1]) : ]\n",
    "train_Y , test_Y = Y[:, : int( (train_split_percent/100)*X.shape[1])] , Y[:,int( (train_split_percent/100)*X.shape[1]) : ]\n",
    "print(\"Seed of Randomization   : \"+str(seed))\n",
    "print(\"\\nShape of Training set X : \"+str(train_X.shape))\n",
    "print(\"Shape of Training set Y : \"+str(train_Y.shape))\n",
    "print(\"\\nShape of Test set   X   : \"+str(test_X.shape))\n",
    "print(\"Shape of Test set Y     : \"+str(test_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training examples : 1168\n",
      "No of test example      : 292\n"
     ]
    }
   ],
   "source": [
    "m_train = train_X.shape[1]\n",
    "m_test  = test_X.shape[1]\n",
    "print(\"No of training examples : \"+str(m_train))\n",
    "print(\"No of test example      : \"+str(m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"\n",
    "    Input  :  Numpy array x \n",
    "    Output :  Numpy array of same shape as X but standardized along each rows\n",
    "    \n",
    "    \"\"\"\n",
    "    x_mean = np.mean(x,axis=1, keepdims=True)\n",
    "    x_std = np.std(x, axis=1, keepdims=True)\n",
    "\n",
    "    #print(\"Mean of each row : \\n\\n\"+str(x_mean))\n",
    "    #print(\"\\nStandard deviation of each row : \\n\\n\"+str(x_std))\n",
    "\n",
    "    X = (x - x_mean)/x_std   #Python Broadcasting\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardize train_X : (10, 1168)\n",
      "\n",
      "[[ 2.23367899 -0.10698965 -0.35693162 ... -0.44731467 -0.10547485\n",
      "   0.05761859]\n",
      " [-0.1092216  -0.1092216  -0.82190776 ... -1.53459392  0.60346457\n",
      "  -0.1092216 ]\n",
      " [-2.30141054  1.25773876 -1.41162321 ...  1.25773876 -0.52183589\n",
      "   0.36795144]\n",
      " ...\n",
      " [ 1.49172485 -0.94681206 -0.94681206 ... -0.33717784  0.88209062\n",
      "  -0.33717784]\n",
      " [ 2.13529354  2.13529354  0.58621102 ... -0.9628715   0.58621102\n",
      "  -0.9628715 ]\n",
      " [ 0.0308818  -1.08416503 -0.57234026 ... -1.08416503 -0.19761141\n",
      "   0.17711745]]\n",
      "\n",
      "\n",
      "Standardize test_X : (10, 292)\n",
      "\n",
      "[[ 0.00911413 -0.15441423 -0.0605801  ... -0.14176025 -0.69989814\n",
      "   0.62137212]\n",
      " [ 0.87623012 -1.47830235 -0.69345819 ...  0.09138596  0.87623012\n",
      "   0.87623012]\n",
      " [ 0.44085645  1.38049211  1.38049211 ... -0.4987792  -0.4987792\n",
      "  -0.4987792 ]\n",
      " ...\n",
      " [ 1.04502677  0.40125501 -0.88628853 ...  1.04502677  0.40125501\n",
      "   0.40125501]\n",
      " [ 0.65932079 -0.90589605 -0.90589605 ... -0.90589605  0.65932079\n",
      "  -0.90589605]\n",
      " [ 0.14167258 -2.38627965 -0.03104465 ...  0.43476849 -0.18806032\n",
      "   0.15737415]]\n"
     ]
    }
   ],
   "source": [
    "train_X = standardize(train_X)\n",
    "print(\"Standardize train_X : \"+str(train_X.shape)+\"\\n\\n\"+str(train_X))\n",
    "test_X  = standardize(test_X)\n",
    "print(\"\\n\\nStandardize test_X : \"+str(test_X.shape)+\"\\n\\n\"+str(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \n",
    "    W1 = np.random.randn(n_h,n_x)*0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            \n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "   \n",
    "    Z = np.dot(W,A)+b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = sigmoid(Z), sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z), relu(Z)\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "        \n",
    "    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)],activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    cost = (-1/m)*(np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL)))\n",
    "    cost = np.squeeze(cost)     \n",
    "   \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "    \n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    current_cache = caches[-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \n",
    "    L = len(parameters) // 2 \n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [10,5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.003, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "\n",
    "    costs = []                      \n",
    "    \n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    " \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693254\n",
      "Cost after iteration 100: 0.693117\n",
      "Cost after iteration 200: 0.692996\n",
      "Cost after iteration 300: 0.692868\n",
      "Cost after iteration 400: 0.692704\n",
      "Cost after iteration 500: 0.692464\n",
      "Cost after iteration 600: 0.692089\n",
      "Cost after iteration 700: 0.691476\n",
      "Cost after iteration 800: 0.690465\n",
      "Cost after iteration 900: 0.688796\n",
      "Cost after iteration 1000: 0.686052\n",
      "Cost after iteration 1100: 0.681568\n",
      "Cost after iteration 1200: 0.674334\n",
      "Cost after iteration 1300: 0.662878\n",
      "Cost after iteration 1400: 0.645238\n",
      "Cost after iteration 1500: 0.619245\n",
      "Cost after iteration 1600: 0.583206\n",
      "Cost after iteration 1700: 0.537201\n",
      "Cost after iteration 1800: 0.484246\n",
      "Cost after iteration 1900: 0.430496\n",
      "Cost after iteration 2000: 0.383436\n",
      "Cost after iteration 2100: 0.347534\n",
      "Cost after iteration 2200: 0.321766\n",
      "Cost after iteration 2300: 0.303092\n",
      "Cost after iteration 2400: 0.288442\n",
      "Cost after iteration 2500: 0.275520\n",
      "Cost after iteration 2600: 0.264190\n",
      "Cost after iteration 2700: 0.255202\n",
      "Cost after iteration 2800: 0.248566\n",
      "Cost after iteration 2900: 0.244909\n",
      "Cost after iteration 3000: 0.243395\n",
      "Cost after iteration 3100: 0.243176\n",
      "Cost after iteration 3200: 0.243611\n",
      "Cost after iteration 3300: 0.244521\n",
      "Cost after iteration 3400: 0.245561\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 89.72602739726028 %\n",
      "Test Accuracy = 88.35616438356165 %\n"
     ]
    }
   ],
   "source": [
    "parameters = L_layer_model(train_X, train_Y, layers_dims = [10,8,1], num_iterations = 3500, learning_rate = 0.007, print_cost = True)\n",
    "\n",
    "def predict(X,parameters):\n",
    "    \n",
    "    AL = L_model_forward(X, parameters)[0]\n",
    "    Y_prediction = AL\n",
    "    for i in range(AL.shape[1]):\n",
    "          Y_prediction[0, i] = 1 if AL[0, i] > 0.5 else 0\n",
    "   \n",
    "    return Y_prediction \n",
    "\n",
    "test_Yhat = predict(test_X,parameters)\n",
    "train_Yhat = predict(train_X,parameters)\n",
    "\n",
    "test_accuracy =  np.mean(test_Yhat == test_Y)\n",
    "train_accuracy = np.mean(train_Yhat == train_Y)\n",
    "\n",
    "print(\"Train Accuracy = \"+str(train_accuracy*100)+\" %\")\n",
    "print(\"Test Accuracy = \"+str(test_accuracy*100)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
