{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : \n",
      "\n",
      "[[8.450e+03 7.000e+00 5.000e+00 ... 0.000e+00 5.480e+02 1.000e+00]\n",
      " [9.600e+03 6.000e+00 8.000e+00 ... 1.000e+00 4.600e+02 1.000e+00]\n",
      " [1.125e+04 7.000e+00 5.000e+00 ... 1.000e+00 6.080e+02 1.000e+00]\n",
      " ...\n",
      " [9.042e+03 7.000e+00 9.000e+00 ... 2.000e+00 2.520e+02 1.000e+00]\n",
      " [9.717e+03 5.000e+00 6.000e+00 ... 0.000e+00 2.400e+02 0.000e+00]\n",
      " [9.937e+03 5.000e+00 6.000e+00 ... 0.000e+00 2.760e+02 0.000e+00]]\n",
      "\n",
      "Dimensions of dataset : (1460, 11)\n"
     ]
    }
   ],
   "source": [
    "data_orig = np.genfromtxt('data/housepricedata.csv',delimiter=',',skip_header=1)\n",
    "print(\"Dataset : \\n\\n\"+ str(data_orig))\n",
    "print(\"\\nDimensions of dataset : \"+str(data_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed for np.random\n",
    "seed=9\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling imported original dataset\n",
    "np.random.shuffle(data_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled dataset with (Seed 9) :\n",
      "\n",
      "[[3.9640e+03 6.0000e+00 4.0000e+00 ... 1.0000e+00 5.7600e+02 0.0000e+00]\n",
      " [3.9104e+04 7.0000e+00 7.0000e+00 ... 2.0000e+00 4.3900e+02 1.0000e+00]\n",
      " [6.0400e+03 4.0000e+00 5.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [8.7770e+03 5.0000e+00 7.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.4480e+03 7.0000e+00 5.0000e+00 ... 0.0000e+00 4.7400e+02 0.0000e+00]\n",
      " [9.2450e+03 7.0000e+00 5.0000e+00 ... 0.0000e+00 6.3900e+02 1.0000e+00]]\n",
      "\n",
      "(1460, 11)\n"
     ]
    }
   ],
   "source": [
    "#Shuffled dataset\n",
    "print(\"Shuffled dataset with (Seed \"+str(seed) +\") :\\n\\n\"+str(data_orig))\n",
    "print(\"\\n\"+str(data_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Y   :[0. 1. 0. ... 0. 0. 1.]\n",
      "Shape of Y : (1460,)\n"
     ]
    }
   ],
   "source": [
    "#Extacting Y\n",
    "y_orig = data_orig[:,-1]\n",
    "print(\"Output Y   :\"+str(y_orig))\n",
    "print(\"Shape of Y : \"+str(y_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (1, 1460)\n"
     ]
    }
   ],
   "source": [
    "Y = np.reshape(y_orig,(y_orig.shape[0],1)).T    \n",
    "print(\"Shape of Y: \"+ str(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input set : \n",
      "\n",
      "[[3.9640e+03 3.9104e+04 6.0400e+03 ... 8.7770e+03 2.4480e+03 9.2450e+03]\n",
      " [6.0000e+00 7.0000e+00 4.0000e+00 ... 5.0000e+00 7.0000e+00 7.0000e+00]\n",
      " [4.0000e+00 7.0000e+00 5.0000e+00 ... 7.0000e+00 5.0000e+00 5.0000e+00]\n",
      " ...\n",
      " [1.0000e+01 5.0000e+00 6.0000e+00 ... 4.0000e+00 6.0000e+00 8.0000e+00]\n",
      " [1.0000e+00 2.0000e+00 0.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [5.7600e+02 4.3900e+02 0.0000e+00 ... 0.0000e+00 4.7400e+02 6.3900e+02]]\n"
     ]
    }
   ],
   "source": [
    "#Extracting vectorized input feature X (transposed)\n",
    "x_shuffled = data_orig[:,0:-1].T\n",
    "print(\"Input set : \\n\\n\" +str(x_shuffled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1460)\n"
     ]
    }
   ],
   "source": [
    "print(x_shuffled.shape)\n",
    "X=x_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed of Randomization   : 9\n",
      "\n",
      "Shape of Training set X : (10, 1168)\n",
      "Shape of Training set Y : (1, 1168)\n",
      "\n",
      "Shape of Test set   X   : (10, 292)\n",
      "Shape of Test set Y     : (1, 292)\n"
     ]
    }
   ],
   "source": [
    "#Splitting into Train, Test sets ( with a fixed seed )\n",
    "train_split_percent = 80\n",
    "test_split_percent = 20\n",
    "\n",
    "train_X , test_X = X[:, : int( (train_split_percent/100)*X.shape[1])] , X[:,int( (train_split_percent/100)*X.shape[1]) : ]\n",
    "train_Y , test_Y = Y[:, : int( (train_split_percent/100)*X.shape[1])] , Y[:,int( (train_split_percent/100)*X.shape[1]) : ]\n",
    "print(\"Seed of Randomization   : \"+str(seed))\n",
    "print(\"\\nShape of Training set X : \"+str(train_X.shape))\n",
    "print(\"Shape of Training set Y : \"+str(train_Y.shape))\n",
    "print(\"\\nShape of Test set   X   : \"+str(test_X.shape))\n",
    "print(\"Shape of Test set Y     : \"+str(test_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training examples : 1168\n",
      "No of test example      : 292\n"
     ]
    }
   ],
   "source": [
    "m_train = train_X.shape[1]\n",
    "m_test  = test_X.shape[1]\n",
    "print(\"No of training examples : \"+str(m_train))\n",
    "print(\"No of test example      : \"+str(m_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"\n",
    "    Input  :  Numpy array x \n",
    "    Output :  Numpy array of same shape as X but standardized along each rows\n",
    "    \n",
    "    \"\"\"\n",
    "    x_mean = np.mean(x,axis=1, keepdims=True)\n",
    "    x_std = np.std(x, axis=1, keepdims=True)+0.0000001\n",
    "\n",
    "    #print(\"Mean of each row : \\n\\n\"+str(x_mean))\n",
    "    #print(\"\\nStandard deviation of each row : \\n\\n\"+str(x_std))\n",
    "\n",
    "    X = (x - x_mean)/x_std   #Python Broadcasting\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardize train_X : (10, 1168)\n",
      "\n",
      "[[-0.62294439  2.64369886 -0.42995773 ... -0.07112896  0.33101956\n",
      "  -0.14224398]\n",
      " [-0.06530135  0.66109842 -1.51810088 ...  0.66109842  1.38749818\n",
      "  -0.06530135]\n",
      " [-1.39247973  1.28548348 -0.49982533 ... -0.49982533 -0.49982533\n",
      "  -0.49982533]\n",
      " ...\n",
      " [ 2.17516177 -0.9261431  -0.30588212 ...  1.5549008   1.5549008\n",
      "   0.31437885]\n",
      " [ 0.59351659  2.15836393 -0.97133075 ...  0.59351659  0.59351659\n",
      "  -0.97133075]\n",
      " [ 0.48109632 -0.16278512 -2.22602564 ...  0.85708548  1.9803531\n",
      "   0.33070066]]\n",
      "\n",
      "\n",
      "Standardize test_X : (10, 292)\n",
      "\n",
      "[[-0.09938328  0.03686526 -0.32759958 ... -0.19526819 -1.27316445\n",
      "  -0.11556279]\n",
      " [-1.52084785 -0.09749025 -0.09749025 ... -0.80916905  0.61418856\n",
      "   0.61418856]\n",
      " [ 0.33665216 -0.59072927 -0.59072927 ...  1.26403359 -0.59072927\n",
      "  -0.59072927]\n",
      " ...\n",
      " [-1.56607364  0.22958148  0.82813318 ... -1.56607364 -0.36897023\n",
      "   0.82813318]\n",
      " [-0.87582337  0.62853206  0.62853206 ... -0.87582337 -0.87582337\n",
      "  -0.87582337]\n",
      " [-1.08665717  0.03514285 -0.18094158 ... -2.16248178  0.01675268\n",
      "   0.77534696]]\n"
     ]
    }
   ],
   "source": [
    "train_X = standardize(train_X)\n",
    "print(\"Standardize train_X : \"+str(train_X.shape)+\"\\n\\n\"+str(train_X))\n",
    "test_X  = standardize(test_X)\n",
    "print(\"\\n\\nStandardize test_X : \"+str(test_X.shape)+\"\\n\\n\"+str(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \n",
    "    W1 = np.random.randn(n_h,n_x)*0.1\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.1\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            \n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*(2/layer_dims[l-1])**0.5\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "   \n",
    "    Z = np.dot(W,A)+b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = sigmoid(Z), sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z), relu(Z)\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "        \n",
    "    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)],activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    cost = (-1/m)*(np.sum(Y*np.log(AL+0.0000001)+(1-Y)*np.log(1.000001-AL)))\n",
    "    cost = np.squeeze(cost)     \n",
    "   \n",
    "    return cost+0.00000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "    \n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    current_cache = caches[-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \n",
    "    L = len(parameters) // 2 \n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.003, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "\n",
    "    costs = []                      \n",
    "    \n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    " \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        if cost <0.25 or math.isnan(cost):\n",
    "            break\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per thousands)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Y,Yhat,Set):\n",
    "    spos=0\n",
    "    \n",
    "    for i in range(Y.shape[1]): \n",
    "        if Y[0,i]==1 and Yhat[0,i]==1:\n",
    "            spos = spos+1\n",
    "            \n",
    "    p = spos /np.sum(Yhat == 1)\n",
    "    r = spos/ np.sum( Y == 1)\n",
    "    acc = np.mean(Y == Yhat)\n",
    "    f1score = 2*p*r/(p+r)\n",
    "    \n",
    "    print(Set+\" :       \"+str(p) + \"  \"+str(r)+\"  \"+str(f1score)+\"  \"+str(acc))\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.623497\n",
      "Cost after iteration 100: 0.617421\n",
      "Cost after iteration 200: 0.611194\n",
      "Cost after iteration 300: 0.604830\n",
      "Cost after iteration 400: 0.598416\n",
      "Cost after iteration 500: 0.591985\n",
      "Cost after iteration 600: 0.585465\n",
      "Cost after iteration 700: 0.578838\n",
      "Cost after iteration 800: 0.572143\n",
      "Cost after iteration 900: 0.565475\n",
      "Cost after iteration 1000: 0.558907\n",
      "Cost after iteration 1100: 0.552487\n",
      "Cost after iteration 1200: 0.546128\n",
      "Cost after iteration 1300: 0.539782\n",
      "Cost after iteration 1400: 0.533535\n",
      "Cost after iteration 1500: 0.527384\n",
      "Cost after iteration 1600: 0.521430\n",
      "Cost after iteration 1700: 0.515639\n",
      "Cost after iteration 1800: 0.510116\n",
      "Cost after iteration 1900: 0.504705\n",
      "Cost after iteration 2000: 0.499378\n",
      "Cost after iteration 2100: 0.494248\n",
      "Cost after iteration 2200: 0.489320\n",
      "Cost after iteration 2300: 0.484502\n",
      "Cost after iteration 2400: 0.479785\n",
      "Cost after iteration 2500: 0.475237\n",
      "Cost after iteration 2600: 0.470862\n",
      "Cost after iteration 2700: 0.466547\n",
      "Cost after iteration 2800: 0.462372\n",
      "Cost after iteration 2900: 0.458435\n",
      "Cost after iteration 3000: 0.454642\n",
      "Cost after iteration 3100: 0.451004\n",
      "Cost after iteration 3200: 0.447485\n",
      "Cost after iteration 3300: 0.444115\n",
      "Cost after iteration 3400: 0.440823\n",
      "Cost after iteration 3500: 0.437589\n",
      "Cost after iteration 3600: 0.434468\n",
      "Cost after iteration 3700: 0.431466\n",
      "Cost after iteration 3800: 0.428558\n",
      "Cost after iteration 3900: 0.425724\n",
      "Cost after iteration 4000: 0.422977\n",
      "Cost after iteration 4100: 0.420266\n",
      "Cost after iteration 4200: 0.417612\n",
      "Cost after iteration 4300: 0.414995\n",
      "Cost after iteration 4400: 0.412398\n",
      "Cost after iteration 4500: 0.409833\n",
      "Cost after iteration 4600: 0.407301\n",
      "Cost after iteration 4700: 0.404809\n",
      "Cost after iteration 4800: 0.402343\n",
      "Cost after iteration 4900: 0.399918\n",
      "Cost after iteration 5000: 0.397535\n",
      "Cost after iteration 5100: 0.395191\n",
      "Cost after iteration 5200: 0.392897\n",
      "Cost after iteration 5300: 0.390635\n",
      "Cost after iteration 5400: 0.388401\n",
      "Cost after iteration 5500: 0.386196\n",
      "Cost after iteration 5600: 0.384043\n",
      "Cost after iteration 5700: 0.381936\n",
      "Cost after iteration 5800: 0.379868\n",
      "Cost after iteration 5900: 0.377807\n",
      "Cost after iteration 6000: 0.375747\n",
      "Cost after iteration 6100: 0.373709\n",
      "Cost after iteration 6200: 0.371703\n",
      "Cost after iteration 6300: 0.369729\n",
      "Cost after iteration 6400: 0.367787\n",
      "Cost after iteration 6500: 0.365882\n",
      "Cost after iteration 6600: 0.364043\n",
      "Cost after iteration 6700: 0.362228\n",
      "Cost after iteration 6800: 0.360444\n",
      "Cost after iteration 6900: 0.358677\n",
      "Cost after iteration 7000: 0.356866\n",
      "Cost after iteration 7100: 0.355034\n",
      "Cost after iteration 7200: 0.353240\n",
      "Cost after iteration 7300: 0.351472\n",
      "Cost after iteration 7400: 0.349649\n",
      "Cost after iteration 7500: 0.347827\n",
      "Cost after iteration 7600: 0.346089\n",
      "Cost after iteration 7700: 0.344382\n",
      "Cost after iteration 7800: 0.342635\n",
      "Cost after iteration 7900: 0.340929\n",
      "Cost after iteration 8000: 0.339222\n",
      "Cost after iteration 8100: 0.337573\n",
      "Cost after iteration 8200: 0.335963\n",
      "Cost after iteration 8300: 0.334310\n",
      "Cost after iteration 8400: 0.332729\n",
      "Cost after iteration 8500: 0.331208\n",
      "Cost after iteration 8600: 0.329601\n",
      "Cost after iteration 8700: 0.328153\n",
      "Cost after iteration 8800: 0.326808\n",
      "Cost after iteration 8900: 0.325552\n",
      "Cost after iteration 9000: 0.324377\n",
      "Cost after iteration 9100: 0.323230\n",
      "Cost after iteration 9200: 0.322162\n",
      "Cost after iteration 9300: 0.321163\n",
      "Cost after iteration 9400: 0.320206\n",
      "Cost after iteration 9500: 0.319314\n",
      "Cost after iteration 9600: 0.318468\n",
      "Cost after iteration 9700: 0.317653\n",
      "Cost after iteration 9800: 0.316901\n",
      "Cost after iteration 9900: 0.316196\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     :       \t Precision        \tRecall            F-score            Accuracy\n",
      "Train :       0.9232142857142858  0.8807495741056218  0.9014821272885789  0.9032534246575342\n",
      "Test  :       0.9166666666666666  0.8581560283687943  0.8864468864468864  0.8938356164383562\n"
     ]
    }
   ],
   "source": [
    "parameters = L_layer_model(train_X, train_Y, layers_dims = [10,15,10,5,1], num_iterations =10000, learning_rate = 0.001, print_cost = True)\n",
    "\n",
    "def predict(X,parameters):\n",
    "    \n",
    "    AL = L_model_forward(X, parameters)[0]\n",
    "    Y_prediction = AL\n",
    "    for i in range(AL.shape[1]):\n",
    "          Y_prediction[0, i] = 1 if AL[0, i] > 0.5 else 0\n",
    "   \n",
    "    return Y_prediction \n",
    "\n",
    "test_Yhat = predict(test_X,parameters)\n",
    "train_Yhat = predict(train_X,parameters)\n",
    "\n",
    "\n",
    "print(\"    \"+\" :       \"+ \"\\t Precision \" + \"  \"+ \"     \\tRecall\" +\"  \"+\"          F-score \"+\"  \"+\"         Accuracy\")\n",
    "\n",
    "evaluate(train_Y,train_Yhat,\"Train\")\n",
    "evaluate(test_Y,test_Yhat,\"Test \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
